{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21f992d1-1f02-4cae-9c20-7d460fdbaf84",
   "metadata": {
    "_sphinx_cell_id": "8f54dfbb-15f0-4874-84a8-f60c4d91ce67"
   },
   "source": [
    "## MCP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e9239d-8734-4540-adc8-053502c2aaa5",
   "metadata": {
    "_sphinx_cell_id": "f3355b2a-e4d3-4396-b8e0-235e5c92fa7e"
   },
   "source": [
    "agent <-> MCP server <-> tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "664603bd-b21f-4aea-84d0-d1cc432db98b",
   "metadata": {
    "_sphinx_cell_id": "6ea41423-7995-447f-b1dd-c61e5b0e1522"
   },
   "outputs": [],
   "source": [
    "from toyaikit.mcp import MCPClient, SubprocessMCPTransport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c87b89cd-48c0-48d1-ad15-1663ad981165",
   "metadata": {
    "_sphinx_cell_id": "4329cfee-05e4-429d-88ef-f5f890818f45"
   },
   "outputs": [],
   "source": [
    "command = \"uv run python main.py\".split()\n",
    "workdir = \"mcp_faq\"\n",
    "\n",
    "client = MCPClient(\n",
    "    transport=SubprocessMCPTransport(\n",
    "        server_command=command,\n",
    "        workdir=workdir\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7151143a-a6a3-4bae-8117-c5e61f128476",
   "metadata": {
    "_sphinx_cell_id": "1bd52b18-798b-4f5a-a040-82650978b4e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started server with command: uv run python main.py\n"
     ]
    }
   ],
   "source": [
    "client.start_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dd7ead6b-8daa-49b9-a3c3-cdf4060a0338",
   "metadata": {
    "_sphinx_cell_id": "93bb51f7-29a2-41dd-ad68-87c189168c28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending initialize request...\n",
      "Initialize response: {'protocolVersion': '2024-11-05', 'capabilities': {'experimental': {}, 'prompts': {'listChanged': False}, 'resources': {'subscribe': False, 'listChanged': False}, 'tools': {'listChanged': True}}, 'serverInfo': {'name': 'Demo ðŸš€', 'version': '1.13.1'}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'protocolVersion': '2024-11-05',\n",
       " 'capabilities': {'experimental': {},\n",
       "  'prompts': {'listChanged': False},\n",
       "  'resources': {'subscribe': False, 'listChanged': False},\n",
       "  'tools': {'listChanged': True}},\n",
       " 'serverInfo': {'name': 'Demo ðŸš€', 'version': '1.13.1'}}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "247d5d44-c3b5-4372-8b9b-a09c8b463ea6",
   "metadata": {
    "_sphinx_cell_id": "51dd51a4-80ec-4d41-837b-373806a930a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending initialized notification...\n",
      "Handshake completed successfully\n"
     ]
    }
   ],
   "source": [
    "client.initialized()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b711b32f-cad2-40ea-958e-458d7be99db2",
   "metadata": {
    "_sphinx_cell_id": "75c356f0-70a4-4226-b638-64196ae526b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving available tools...\n",
      "Available tools: ['add_entry', 'search']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'name': 'add_entry',\n",
       "  'description': 'Add a new entry to the FAQ database.\\n\\nArgs:\\n    question (str): The question to be added to the FAQ database.\\n    answer (str): The corresponding answer to the question.',\n",
       "  'inputSchema': {'properties': {'question': {'title': 'Question',\n",
       "     'type': 'string'},\n",
       "    'answer': {'title': 'Answer', 'type': 'string'}},\n",
       "   'required': ['question', 'answer'],\n",
       "   'type': 'object'},\n",
       "  '_meta': {'_fastmcp': {'tags': []}}},\n",
       " {'name': 'search',\n",
       "  'description': 'Search the FAQ database for entries matching the given query.\\n\\nArgs:\\n    query (str): Search query text to look up in the course FAQ.\\n\\nReturns:\\n    List[Dict[str, Any]]: A list of search result entries, each containing relevant metadata.',\n",
       "  'inputSchema': {'properties': {'query': {'title': 'Query',\n",
       "     'type': 'string'}},\n",
       "   'required': ['query'],\n",
       "   'type': 'object'},\n",
       "  'outputSchema': {'properties': {'result': {'items': {'additionalProperties': True,\n",
       "      'type': 'object'},\n",
       "     'title': 'Result',\n",
       "     'type': 'array'}},\n",
       "   'required': ['result'],\n",
       "   'title': '_WrappedResult',\n",
       "   'type': 'object',\n",
       "   'x-fastmcp-wrap-result': True},\n",
       "  '_meta': {'_fastmcp': {'tags': []}}}]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d7c94e49-c900-495a-aac1-080e6f6c62dd",
   "metadata": {
    "_sphinx_cell_id": "593afd0d-8fd1-47d9-840d-bfafaac3f6ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling tool 'search' with arguments: {'query': 'how do I run docker?'}\n"
     ]
    }
   ],
   "source": [
    "result = client.call_tool('search', {'query': 'how do I run docker?'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b2bf9f6e-e946-4f97-95f2-0491a45f445f",
   "metadata": {
    "_sphinx_cell_id": "5cc23e85-4c8e-40a9-ae54-4f63c8b8d67b"
   },
   "outputs": [],
   "source": [
    "from toyaikit.mcp import MCPTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3113b060-d19f-44a7-9c2e-4ad10ea3d76f",
   "metadata": {
    "_sphinx_cell_id": "0b2a8fdd-504e-4838-809d-50da57481d07"
   },
   "outputs": [],
   "source": [
    "mcp_tools = MCPTools(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5ce1397a-87c8-471a-8d39-626a5c1eec14",
   "metadata": {
    "_sphinx_cell_id": "15a6d77a-02db-401d-942b-5bef7d79c690"
   },
   "outputs": [],
   "source": [
    "runner = OpenAIResponsesRunner(\n",
    "    tools=mcp_tools,\n",
    "    developer_prompt=developer_prompt,\n",
    "    chat_interface=chat_interface,\n",
    "    llm_client=OpenAIClient(model='gpt-4o-mini')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ffeddb4e-86d3-4bad-81c0-60583acc10d0",
   "metadata": {
    "_sphinx_cell_id": "6ab17edd-ebd1-40cd-a5c9-57a4c90868a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You: how do I insall kafka?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling tool 'search' with arguments: {'query': 'install Kafka'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>search({\"query\":\"install Kafka\"})</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>{\"query\":\"install Kafka\"}</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>{'type': 'function_call_output', 'call_id': 'call_Mvc7onXzmltK2P0RvjlXLT6X', 'output': '[{\"text\":\"confluent-kafka: `pip install confluent-kafka` or `conda install conda-forge::python-confluent-kafka`\\\\nfastavro: pip install fastavro\\\\nAbhirup Ghosh\\\\nCan install Faust Library for Module 6 Python Version due to dependency conflicts?\\\\nThe Faust repository and library is no longer maintained - https://github.com/robinhood/faust\\\\nIf you do not know Java, you now have the option to follow the Python Videos 6.13 & 6.14 here https://www.youtube.com/watch?v=BgAlVknDFlQ&list=PL3MmuxUbc_hJed7dXYoJw8DoCuVHhGEQb&index=80  and follow the RedPanda Python version here https://github.com/DataTalksClub/data-engineering-zoomcamp/tree/main/06-streaming/python/redpanda_example - NOTE: I highly recommend watching the Java videos to understand the concept of streaming but you can skip the coding parts - all will become clear when you get to the Python videos and RedPanda files.\",\"section\":\"Module 6: streaming with kafka\",\"question\":\"Python Kafka: Installing dependencies for python3 06-streaming/python/avro_example/producer.py\",\"course\":\"data-engineering-zoomcamp\"},{\"text\":\"In my set up, all of the dependencies listed in gradle.build were not installed in <project_name>-1.0-SNAPSHOT.jar.\\\\nSolution:\\\\nIn build.gradle file, I added the following at the end:\\\\nshadowJar {\\\\narchiveBaseName = \\\\\"java-kafka-rides\\\\\"\\\\narchiveClassifier = \\'\\'\\\\n}\\\\nAnd then in the command line ran â€˜gradle shadowjarâ€™, and run the script from java-kafka-rides-1.0-SNAPSHOT.jar created by the shadowjar\",\"section\":\"Module 6: streaming with kafka\",\"question\":\"Java Kafka: <project_name>-1.0-SNAPSHOT.jar errors: package xxx does not exist even after gradle build\",\"course\":\"data-engineering-zoomcamp\"},{\"text\":\"tip:As the videos have low audio so I downloaded them and used VLC media player with putting the audio to the max 200% of original audio and the audio became quite good or try to use auto caption generated on Youtube directly.\\\\nKafka Python Videos - Rides.csv\\\\nThere is no clear explanation of the rides.csv data that the producer.py python programs use. You can find that here https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/2bd33e89906181e424f7b12a299b70b19b7cfcd5/week_6_stream_processing/python/resources/rides.csv.\",\"section\":\"Module 6: streaming with kafka\",\"question\":\"Kafka- python videos have low audio and hard to follow up\",\"course\":\"data-engineering-zoomcamp\"},{\"text\":\"If you have this error, it most likely that your kafka broker docker container is not working.\\\\nUse docker ps to confirm\\\\nThen in the docker compose yaml file folder, run docker compose up -d to start all the instances.\",\"section\":\"Module 6: streaming with kafka\",\"question\":\"kafka.errors.NoBrokersAvailable: NoBrokersAvailable\",\"course\":\"data-engineering-zoomcamp\"},{\"text\":\"For example, when running JsonConsumer.java, got:\\\\nConsuming form kafka started\\\\nRESULTS:::0\\\\nRESULTS:::0\\\\nRESULTS:::0\\\\nOr when running JsonProducer.java, got:\\\\nException in thread \\\\\"main\\\\\" java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.SaslAuthenticationException: Authentication failed\\\\nSolution:\\\\nMake sure in the scripts in src/main/java/org/example/ that you are running (e.g. JsonConsumer.java, JsonProducer.java), the StreamsConfig.BOOTSTRAP_SERVERS_CONFIG is the correct server url (e.g. europe-west3 from example vs europe-west2)\\\\nMake sure cluster key and secrets are updated in src/main/java/org/example/Secrets.java (KAFKA_CLUSTER_KEY and KAFKA_CLUSTER_SECRET)\",\"section\":\"Module 6: streaming with kafka\",\"question\":\"Java Kafka: When running the producer/consumer/etc java scripts, no results retrieved or no message sent\",\"course\":\"data-engineering-zoomcamp\"}]'}</pre>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling tool 'search' with arguments: {'query': 'Kafka installation guide'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>search({\"query\":\"Kafka installation guide\"})</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>{\"query\":\"Kafka installation guide\"}</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>{'type': 'function_call_output', 'call_id': 'call_PKPYFpvKlGEPPKSAgFgQe7j5', 'output': '[{\"text\":\"tip:As the videos have low audio so I downloaded them and used VLC media player with putting the audio to the max 200% of original audio and the audio became quite good or try to use auto caption generated on Youtube directly.\\\\nKafka Python Videos - Rides.csv\\\\nThere is no clear explanation of the rides.csv data that the producer.py python programs use. You can find that here https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/2bd33e89906181e424f7b12a299b70b19b7cfcd5/week_6_stream_processing/python/resources/rides.csv.\",\"section\":\"Module 6: streaming with kafka\",\"question\":\"Kafka- python videos have low audio and hard to follow up\",\"course\":\"data-engineering-zoomcamp\"},{\"text\":\"If you have this error, it most likely that your kafka broker docker container is not working.\\\\nUse docker ps to confirm\\\\nThen in the docker compose yaml file folder, run docker compose up -d to start all the instances.\",\"section\":\"Module 6: streaming with kafka\",\"question\":\"kafka.errors.NoBrokersAvailable: NoBrokersAvailable\",\"course\":\"data-engineering-zoomcamp\"},{\"text\":\"confluent-kafka: `pip install confluent-kafka` or `conda install conda-forge::python-confluent-kafka`\\\\nfastavro: pip install fastavro\\\\nAbhirup Ghosh\\\\nCan install Faust Library for Module 6 Python Version due to dependency conflicts?\\\\nThe Faust repository and library is no longer maintained - https://github.com/robinhood/faust\\\\nIf you do not know Java, you now have the option to follow the Python Videos 6.13 & 6.14 here https://www.youtube.com/watch?v=BgAlVknDFlQ&list=PL3MmuxUbc_hJed7dXYoJw8DoCuVHhGEQb&index=80  and follow the RedPanda Python version here https://github.com/DataTalksClub/data-engineering-zoomcamp/tree/main/06-streaming/python/redpanda_example - NOTE: I highly recommend watching the Java videos to understand the concept of streaming but you can skip the coding parts - all will become clear when you get to the Python videos and RedPanda files.\",\"section\":\"Module 6: streaming with kafka\",\"question\":\"Python Kafka: Installing dependencies for python3 06-streaming/python/avro_example/producer.py\",\"course\":\"data-engineering-zoomcamp\"},{\"text\":\"In my set up, all of the dependencies listed in gradle.build were not installed in <project_name>-1.0-SNAPSHOT.jar.\\\\nSolution:\\\\nIn build.gradle file, I added the following at the end:\\\\nshadowJar {\\\\narchiveBaseName = \\\\\"java-kafka-rides\\\\\"\\\\narchiveClassifier = \\'\\'\\\\n}\\\\nAnd then in the command line ran â€˜gradle shadowjarâ€™, and run the script from java-kafka-rides-1.0-SNAPSHOT.jar created by the shadowjar\",\"section\":\"Module 6: streaming with kafka\",\"question\":\"Java Kafka: <project_name>-1.0-SNAPSHOT.jar errors: package xxx does not exist even after gradle build\",\"course\":\"data-engineering-zoomcamp\"},{\"text\":\"For example, when running JsonConsumer.java, got:\\\\nConsuming form kafka started\\\\nRESULTS:::0\\\\nRESULTS:::0\\\\nRESULTS:::0\\\\nOr when running JsonProducer.java, got:\\\\nException in thread \\\\\"main\\\\\" java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.SaslAuthenticationException: Authentication failed\\\\nSolution:\\\\nMake sure in the scripts in src/main/java/org/example/ that you are running (e.g. JsonConsumer.java, JsonProducer.java), the StreamsConfig.BOOTSTRAP_SERVERS_CONFIG is the correct server url (e.g. europe-west3 from example vs europe-west2)\\\\nMake sure cluster key and secrets are updated in src/main/java/org/example/Secrets.java (KAFKA_CLUSTER_KEY and KAFKA_CLUSTER_SECRET)\",\"section\":\"Module 6: streaming with kafka\",\"question\":\"Java Kafka: When running the producer/consumer/etc java scripts, no results retrieved or no message sent\",\"course\":\"data-engineering-zoomcamp\"}]'}</pre>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling tool 'search' with arguments: {'query': 'how to set up Kafka on local machine'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>search({\"query\":\"how to set up Kafka on local machine\"})</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>{\"query\":\"how to set up Kafka on local machine\"}</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>{'type': 'function_call_output', 'call_id': 'call_dRzpKUiD8SdLPTxOAnEGj6FL', 'output': '[{\"text\":\"You can set it up on your laptop or PC if you prefer to work locally from your laptop or PC.\\\\nYou might face some challenges, especially for Windows users. If you face cnd2\\\\nIf you prefer to work on the local machine, you may start with the week 1 Introduction to Docker and follow through.\\\\nHowever, if you prefer to set up a virtual machine, you may start with these first:\\\\nUsing GitHub Codespaces\\\\nSetting up the environment on a cloudV Mcodespace\\\\nI decided to work on a virtual machine because I have different laptops & PCs for my home & office, so I can work on this boot camp virtually anywhere.\",\"section\":\"General course-related questions\",\"question\":\"Environment - Should I use my local machine, GCP, or GitHub Codespaces for my environment?\",\"course\":\"data-engineering-zoomcamp\"},{\"text\":\"In my set up, all of the dependencies listed in gradle.build were not installed in <project_name>-1.0-SNAPSHOT.jar.\\\\nSolution:\\\\nIn build.gradle file, I added the following at the end:\\\\nshadowJar {\\\\narchiveBaseName = \\\\\"java-kafka-rides\\\\\"\\\\narchiveClassifier = \\'\\'\\\\n}\\\\nAnd then in the command line ran â€˜gradle shadowjarâ€™, and run the script from java-kafka-rides-1.0-SNAPSHOT.jar created by the shadowjar\",\"section\":\"Module 6: streaming with kafka\",\"question\":\"Java Kafka: <project_name>-1.0-SNAPSHOT.jar errors: package xxx does not exist even after gradle build\",\"course\":\"data-engineering-zoomcamp\"},{\"text\":\"You can check the version of your local spark using spark-submit --version. In the build.sh file of the Python folder, make sure that SPARK_VERSION matches your local version. Similarly, make sure the pyspark you pip installed also matches this version.\",\"section\":\"Module 6: streaming with kafka\",\"question\":\"How do I check compatibility of local and container Spark versions?\",\"course\":\"data-engineering-zoomcamp\"},{\"text\":\"If you have this error, it most likely that your kafka broker docker container is not working.\\\\nUse docker ps to confirm\\\\nThen in the docker compose yaml file folder, run docker compose up -d to start all the instances.\",\"section\":\"Module 6: streaming with kafka\",\"question\":\"kafka.errors.NoBrokersAvailable: NoBrokersAvailable\",\"course\":\"data-engineering-zoomcamp\"},{\"text\":\"tip:As the videos have low audio so I downloaded them and used VLC media player with putting the audio to the max 200% of original audio and the audio became quite good or try to use auto caption generated on Youtube directly.\\\\nKafka Python Videos - Rides.csv\\\\nThere is no clear explanation of the rides.csv data that the producer.py python programs use. You can find that here https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/2bd33e89906181e424f7b12a299b70b19b7cfcd5/week_6_stream_processing/python/resources/rides.csv.\",\"section\":\"Module 6: streaming with kafka\",\"question\":\"Kafka- python videos have low audio and hard to follow up\",\"course\":\"data-engineering-zoomcamp\"}]'}</pre>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>To install Apache Kafka, follow these general steps. Depending on your operating system, the process may vary slightly.</p>\n",
       "<h3>1. <strong>Download Kafka</strong></h3>\n",
       "<ul>\n",
       "<li>Go to the <a href=\"https://kafka.apache.org/downloads\">Apache Kafka download page</a>.</li>\n",
       "<li>Choose the latest version and download the binary files.</li>\n",
       "</ul>\n",
       "<h3>2. <strong>Extract the Files</strong></h3>\n",
       "<ul>\n",
       "<li>Unzip the downloaded file to a directory of your choice.</li>\n",
       "</ul>\n",
       "<h3>3. <strong>Install Java</strong></h3>\n",
       "<p>Kafka requires Java to run. Ensure that you have JDK installed and set the <code>JAVA_HOME</code> environment variable.</p>\n",
       "<h3>4. <strong>Start Zookeeper</strong></h3>\n",
       "<p>Kafka relies on Zookeeper, which is included in its download. Open a terminal and navigate to the Kafka directory. Run the command:</p>\n",
       "<pre><code class=\"language-bash\">bin/zookeeper-server-start.sh config/zookeeper.properties\n",
       "</code></pre>\n",
       "<h3>5. <strong>Start Kafka Server</strong></h3>\n",
       "<p>In a new terminal window, also in the Kafka directory, run:</p>\n",
       "<pre><code class=\"language-bash\">bin/kafka-server-start.sh config/server.properties\n",
       "</code></pre>\n",
       "<h3>6. <strong>Create a Topic</strong></h3>\n",
       "<p>To create a topic named <code>test</code>, run:</p>\n",
       "<pre><code class=\"language-bash\">bin/kafka-topics.sh --create --topic test --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1\n",
       "</code></pre>\n",
       "<h3>7. <strong>Send Messages</strong></h3>\n",
       "<p>You can send messages to the newly created topic with:</p>\n",
       "<pre><code class=\"language-bash\">bin/kafka-console-producer.sh --topic test --bootstrap-server localhost:9092\n",
       "</code></pre>\n",
       "<p>Just type messages and hit enter to send.</p>\n",
       "<h3>8. <strong>Consume Messages</strong></h3>\n",
       "<p>In another terminal, you can consume messages with:</p>\n",
       "<pre><code class=\"language-bash\">bin/kafka-console-consumer.sh --topic test --from-beginning --bootstrap-server localhost:9092\n",
       "</code></pre>\n",
       "<h3>Additional Information:</h3>\n",
       "<ul>\n",
       "<li>If you're using <strong>Docker</strong>, you can set up a Kafka instance using Docker Compose.</li>\n",
       "<li>Ensure your firewall allows the ports used by Kafka (default is 9092).</li>\n",
       "</ul>\n",
       "<p>Would you like more details on any specific step or additional areas like Docker installation or configuration settings?</p>\n",
       "</div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You: stop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat ended.\n"
     ]
    }
   ],
   "source": [
    "runner.run();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
