{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69291aa2-b47d-410d-9dd5-4701a0fe96cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b77bc3f-ed72-4cf6-93e3-e4eb45979364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d9181c8-2817-40d3-8741-332a49a4210e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from minsearch import Index\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "01e16fcc-9091-49d6-b21c-d6003e0ed627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c67330d9-e4a8-479a-95e7-9393a4e30e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import docs\n",
    "\n",
    "github_data = docs.read_github_data()\n",
    "parsed_data = docs.parse_data(github_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29083e9d-06f1-432f-b5a7-64ce1ee9312c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_ground_truth = pd.read_csv('../evals/ground_truth_evidently.csv')\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d66efdd-4c1e-4ea2-b8c1-25d8334557c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)\n",
    "\n",
    "\n",
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "                break\n",
    "\n",
    "    return total_score / len(relevance_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fa9c44be-5898-4bea-b611-4b25ea47b9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tiktoken.encoding_for_model('gpt-4o-mini')\n",
    "\n",
    "def calculate_num_tokens(search_results):\n",
    "    rs_json = json.dumps(search_results)\n",
    "    return len(encoder.encode(rs_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "262c2998-6121-49ce-aa92-1ac41ab38eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm \n",
    "\n",
    "def evaluate(\n",
    "        ground_truth,\n",
    "        search_function,\n",
    "        question_column='question',\n",
    "        id_column='filename'\n",
    "):\n",
    "    relevance_total = []\n",
    "    total_number_tokens = []\n",
    "\n",
    "    for q in ground_truth:\n",
    "        doc_id = q[id_column]\n",
    "        results = search_function(q[question_column])\n",
    "\n",
    "        num_tokens = calculate_num_tokens(results)\n",
    "        total_number_tokens.append(num_tokens)\n",
    "\n",
    "        relevance = [d[id_column] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    avg_num_tokens = sum(total_number_tokens) / len(total_number_tokens)\n",
    "    \n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "        'num_tokens': avg_num_tokens\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6ffa73e6-f5f9-4260-88de-2fd6c61d1422",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 2000\n",
    "step = 1000\n",
    "top_k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3414601a-789e-43f3-973f-25fdf47d0d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_params(size, step, top_k):\n",
    "    chunks = docs.chunk_documents(parsed_data, size=size, step=step)\n",
    "    \n",
    "    index = Index(\n",
    "        text_fields=[\"content\", \"filename\", \"title\", \"description\"],\n",
    "    )\n",
    "    \n",
    "    index.fit(chunks)\n",
    "    \n",
    "    def search(query: str):\n",
    "        return index.search(\n",
    "            query=query,\n",
    "            num_results=top_k,\n",
    "        )\n",
    "    \n",
    "    return evaluate(ground_truth, search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5d7738-5993-433e-a825-c43da867e1b6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c5dadd73-0eee-4ea6-8395-9f46e52297c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.6659090909090909,\n",
       " 'mrr': 0.3565785919896001,\n",
       " 'num_tokens': 9355.861363636364}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd5432d-4df8-43f5-be3c-d496d8942b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ab7a35-f054-4f8f-bc70-8d39f30ae20f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "14f3368c-1eaa-4132-8daa-fb03d692d2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'size': 1000, 'step': 1000, 'top_k': 5, 'hit_rate': 0.3795454545454545, 'num_tokens': 1360.0227272727273}\n",
      "{'size': 1000, 'step': 1000, 'top_k': 10, 'hit_rate': 0.4727272727272727, 'num_tokens': 2758.4977272727274}\n",
      "{'size': 1000, 'step': 1000, 'top_k': 15, 'hit_rate': 0.5659090909090909, 'num_tokens': 4120.754545454545}\n",
      "{'size': 2000, 'step': 1000, 'top_k': 5, 'hit_rate': 0.39090909090909093, 'num_tokens': 2514.2204545454547}\n",
      "{'size': 2000, 'step': 1000, 'top_k': 10, 'hit_rate': 0.47954545454545455, 'num_tokens': 5122.143181818182}\n",
      "{'size': 2000, 'step': 1000, 'top_k': 15, 'hit_rate': 0.5636363636363636, 'num_tokens': 7621.579545454545}\n",
      "{'size': 2000, 'step': 2000, 'top_k': 5, 'hit_rate': 0.40454545454545454, 'num_tokens': 2380.3977272727275}\n",
      "{'size': 2000, 'step': 2000, 'top_k': 10, 'hit_rate': 0.5522727272727272, 'num_tokens': 4715.877272727273}\n",
      "{'size': 2000, 'step': 2000, 'top_k': 15, 'hit_rate': 0.6045454545454545, 'num_tokens': 7030.809090909091}\n",
      "{'size': 3000, 'step': 1000, 'top_k': 5, 'hit_rate': 0.39545454545454545, 'num_tokens': 3599.2136363636364}\n",
      "{'size': 3000, 'step': 1000, 'top_k': 10, 'hit_rate': 0.5022727272727273, 'num_tokens': 7288.109090909091}\n",
      "{'size': 3000, 'step': 1000, 'top_k': 15, 'hit_rate': 0.5704545454545454, 'num_tokens': 10896.697727272727}\n",
      "{'size': 3000, 'step': 2000, 'top_k': 5, 'hit_rate': 0.4159090909090909, 'num_tokens': 3465.2909090909093}\n",
      "{'size': 3000, 'step': 2000, 'top_k': 10, 'hit_rate': 0.55, 'num_tokens': 6824.320454545455}\n",
      "{'size': 3000, 'step': 2000, 'top_k': 15, 'hit_rate': 0.6136363636363636, 'num_tokens': 10258.652272727273}\n",
      "{'size': 3000, 'step': 3000, 'top_k': 5, 'hit_rate': 0.4409090909090909, 'num_tokens': 3179.215909090909}\n",
      "{'size': 3000, 'step': 3000, 'top_k': 10, 'hit_rate': 0.5681818181818182, 'num_tokens': 6326.229545454546}\n",
      "{'size': 3000, 'step': 3000, 'top_k': 15, 'hit_rate': 0.634090909090909, 'num_tokens': 9505.179545454546}\n",
      "{'size': 5000, 'step': 1000, 'top_k': 5, 'hit_rate': 0.4068181818181818, 'num_tokens': 5461.184090909091}\n",
      "{'size': 5000, 'step': 1000, 'top_k': 10, 'hit_rate': 0.5159090909090909, 'num_tokens': 11133.147727272728}\n",
      "{'size': 5000, 'step': 1000, 'top_k': 15, 'hit_rate': 0.5568181818181818, 'num_tokens': 16817.39318181818}\n",
      "{'size': 5000, 'step': 2000, 'top_k': 5, 'hit_rate': 0.44545454545454544, 'num_tokens': 5229.404545454546}\n",
      "{'size': 5000, 'step': 2000, 'top_k': 10, 'hit_rate': 0.5590909090909091, 'num_tokens': 10488.861363636364}\n",
      "{'size': 5000, 'step': 2000, 'top_k': 15, 'hit_rate': 0.6204545454545455, 'num_tokens': 15826.48409090909}\n",
      "{'size': 5000, 'step': 3000, 'top_k': 5, 'hit_rate': 0.44772727272727275, 'num_tokens': 5023.504545454545}\n",
      "{'size': 5000, 'step': 3000, 'top_k': 10, 'hit_rate': 0.5863636363636363, 'num_tokens': 10110.204545454546}\n",
      "{'size': 5000, 'step': 3000, 'top_k': 15, 'hit_rate': 0.6477272727272727, 'num_tokens': 15202.281818181818}\n"
     ]
    }
   ],
   "source": [
    "sizes = [1000, 2000, 3000, 5000]\n",
    "steps = [1000, 2000, 3000]\n",
    "top_ks = [5, 10, 15]\n",
    "\n",
    "results = []\n",
    "\n",
    "for size in sizes:\n",
    "    for step in steps:\n",
    "        if step > size:\n",
    "            continue\n",
    "\n",
    "        for top_k in top_ks:\n",
    "            result = evaluate_params(size, step, top_k)\n",
    "            record = {\n",
    "                'size': size,\n",
    "                'step': step,\n",
    "                'top_k': top_k,\n",
    "                'hit_rate': result['hit_rate'],\n",
    "                'num_tokens': result['num_tokens']\n",
    "            }\n",
    "            print(record)\n",
    "            results.append(record)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7e8cbea7-37ac-4027-b967-f4ef7e2038e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_search_eval = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "52818934-083c-4604-8039-3f52ac4bfba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 2\n",
    "beta = 0.5\n",
    "df_search_eval['score'] = df_search_eval.hit_rate ** alpha / (df_search_eval.num_tokens / 1000) ** beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7071de54-6623-4006-9663-86175f422792",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best = df_search_eval.sort_values(by='score', ascending=False).head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8b815f67-2842-4a3b-806d-ce4f31b09535",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_candidates = df_best.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e72e5e4a-297e-469a-9ef1-fd482076b0b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'size': 1000,\n",
       "  'step': 1000,\n",
       "  'top_k': 15,\n",
       "  'hit_rate': 0.5659090909090909,\n",
       "  'num_tokens': 4120.754545454545,\n",
       "  'score': 0.15776293166330635},\n",
       " {'size': 2000,\n",
       "  'step': 2000,\n",
       "  'top_k': 10,\n",
       "  'hit_rate': 0.5522727272727272,\n",
       "  'num_tokens': 4715.877272727273,\n",
       "  'score': 0.1404513594105386},\n",
       " {'size': 2000,\n",
       "  'step': 2000,\n",
       "  'top_k': 15,\n",
       "  'hit_rate': 0.6045454545454545,\n",
       "  'num_tokens': 7030.809090909091,\n",
       "  'score': 0.13783365334705797},\n",
       " {'size': 1000,\n",
       "  'step': 1000,\n",
       "  'top_k': 10,\n",
       "  'hit_rate': 0.4727272727272727,\n",
       "  'num_tokens': 2758.4977272727274,\n",
       "  'score': 0.13455040263772092},\n",
       " {'size': 3000,\n",
       "  'step': 3000,\n",
       "  'top_k': 15,\n",
       "  'hit_rate': 0.634090909090909,\n",
       "  'num_tokens': 9505.179545454546,\n",
       "  'score': 0.13041360229484228}]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1a67dcf-ed96-428b-be3a-f9149e98803b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import search_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5eb8f9a4-6262-4695-aa53-7cb809fd1de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = search_agent.AgentConfig(\n",
    "    chunk_size=1000,\n",
    "    chunk_step=1000,\n",
    "    top_k=15,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e50cb72e-60a7-4f8a-9c74-b3d1526f0dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = search_agent.create_agent(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40e5e1da-8c51-43a9-94c9-287826b83843",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evals.eval_orchestrator import run_full_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b536854e-9066-4b36-a7ad-c03ee38b9b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== EVALUATION PIPELINE START ========================================\n",
      "Start time: 2025-10-27 14:12:20\n",
      "Configuration:\n",
      "  Ground truth: ../evals/gt-sample.csv\n",
      "  Agent model: gpt-4o-mini\n",
      "  Judge model: gpt-5-nano\n",
      "  Max concurrency: 10\n",
      "\n",
      "=== STEP 1: AGENT EVALUATION =========================================\n",
      "Loaded 26 ground truth questions\n",
      "Running agent evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "477d549da18b46fdb789ae748787d4f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forcing output\n",
      "forcing output\n",
      "forcing output\n",
      "forcing output\n",
      "forcing output\n",
      "forcing output\n",
      "forcing output\n",
      "forcing output\n",
      "forcing output\n",
      "forcing output\n",
      "forcing output\n",
      "forcing output\n",
      "forcing output\n",
      "forcing output\n",
      "forcing output\n",
      "Total cost: $0.1451\n",
      "Results saved to reports/eval-run-2025-10-27-14-13.bin\n",
      "\n",
      "✓ Agent evaluation completed\n",
      "  Evaluated: 26 questions\n",
      "  Results saved: reports/eval-run-2025-10-27-14-13.bin\n",
      "  Agent Run Costs:\n",
      "    Input tokens cost:  $  0.1352\n",
      "    Output tokens cost: $  0.0099\n",
      "    Total cost:         $  0.1451\n",
      "\n",
      "=== STEP 2: JUDGE EVALUATION =========================================\n",
      "Loading evaluation results from reports/eval-run-2025-10-27-14-13.bin...\n",
      "Loaded 26 evaluation results\n",
      "Loading reference documents...\n",
      "Creating judge agent...\n",
      "Running judge evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4ce1c0879da4db1ad0648d43c1776ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cost: $0.0252\n",
      "Judge results saved to: reports/eval-judge-2025-10-27-14-13.bin\n",
      "\n",
      "✓ Judge evaluation completed\n",
      "  Evaluated: 26 results\n",
      "  Judge results saved: reports/eval-judge-2025-10-27-14-13.bin\n",
      "  Judge Evaluation Costs:\n",
      "    Input tokens cost:  $  0.0093\n",
      "    Output tokens cost: $  0.0159\n",
      "    Total cost:         $  0.0252\n",
      "\n",
      "=== EVALUATION SUMMARY ===============================================\n",
      "\n",
      "Execution Time:\n",
      "  Duration: 104.1 seconds\n",
      "\n",
      "Dataset:\n",
      "  Questions evaluated: 26\n",
      "\n",
      "Evaluation Metrics:\n",
      "  ✓ CheckName.tool_call_search  92.3%\n",
      "  ✓ CheckName.instructions_follow 100.0%\n",
      "  ✓ CheckName.instructions_avoid 100.0%\n",
      "  ⚠ CheckName.answer_relevant  75.0%\n",
      "  ⚠ CheckName.answer_clear     71.4%\n",
      "  ⚠ CheckName.answer_match     71.4%\n",
      "  ⚠ CheckName.answer_citations  71.4%\n",
      "  ⚠ CheckName.completeness     71.4%\n",
      "\n",
      "Overall Score: 81.6%\n",
      "\n",
      "=== COST BREAKDOWN ===================================================\n",
      "Agent Run Costs:\n",
      "  Input tokens cost:  $  0.1352\n",
      "  Output tokens cost: $  0.0099\n",
      "  Total cost:         $  0.1451\n",
      "Judge Evaluation Costs:\n",
      "  Input tokens cost:  $  0.0093\n",
      "  Output tokens cost: $  0.0159\n",
      "  Total cost:         $  0.0252\n",
      "======================================================================\n",
      "TOTAL Costs:\n",
      "  Input tokens cost:  $  0.1445\n",
      "  Output tokens cost: $  0.0259\n",
      "  Total cost:         $  0.1703\n",
      "\n",
      "=== EVALUATION COMPLETE ==============================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'run_results_path': 'reports/eval-run-2025-10-27-14-13.bin',\n",
       " 'judge_results_path': 'reports/eval-judge-2025-10-27-14-13.bin',\n",
       " 'run_cost': CostInfo(input_cost=0.13517625, output_cost=0.0099498, total_cost=0.14512605),\n",
       " 'judge_cost': CostInfo(input_cost=0.0092816, output_cost=0.015917999999999998, total_cost=0.025199599999999996),\n",
       " 'total_cost': CostInfo(input_cost=0.14445785, output_cost=0.025867799999999996, total_cost=0.17032565),\n",
       " 'df_run':                                              question  \\\n",
       " 0                 how to use TextEvals() in Evidently   \n",
       " 1                          ColumnCount() metric usage   \n",
       " 2                     LLM judge metrics customization   \n",
       " 3                   Evidently telemetry version 0.4.0   \n",
       " 4   how to benchmark model quality with dummy metrics   \n",
       " 5                         examples of JSONSchemaMatch   \n",
       " 6               performing quality checks on datasets   \n",
       " 7                 examples of incorrect LLM responses   \n",
       " 8   example of mapping regression columns in Evide...   \n",
       " 9                  data quality checks with evidently   \n",
       " 10                 HuggingFace emotion classification   \n",
       " 11                  how to create a custom descriptor   \n",
       " 12  best practices for implementing regression met...   \n",
       " 13                       parameters needed for NDCG()   \n",
       " 14                   custom parameters for data drift   \n",
       " 15                   how to implement QuantileValue()   \n",
       " 16               how to run DataDriftPreset in Python   \n",
       " 17                       multiple conditions in tests   \n",
       " 18                     Tracely library real-time data   \n",
       " 19       Impact of telemetry on Evidently development   \n",
       " 20              examples of ValueStats() metric usage   \n",
       " 21                       get reports from LLM testing   \n",
       " 22              creating RAG evaluation dataset guide   \n",
       " 23                  how to exclude tests in evidently   \n",
       " 24         automatically mapping columns in Evidently   \n",
       " 25          use of BinaryClassificationPromptTemplate   \n",
       " \n",
       "                                                answer  \\\n",
       " 0   # Using TextEvals in Evidently\\n\\n## Overview\\...   \n",
       " 1   # ColumnCount Metric Usage\\n\\n## Overview\\n\\nI...   \n",
       " 2   # LLM Metrics Customization\\n\\n## Overview\\n\\n...   \n",
       " 3   # Evidently Telemetry Version 0.4.0\\n\\n## Over...   \n",
       " 4   # Benchmarking Model Quality with Dummy Metric...   \n",
       " 5   # JSONSchemaMatch Examples\\n\\n## Usage of JSON...   \n",
       " 6   # Performing Quality Checks on Datasets with E...   \n",
       " 7   # Examples of Incorrect LLM Responses\\n\\n## Ov...   \n",
       " 8   # Mapping Regression Columns in Evidently\\n\\n#...   \n",
       " 9   # Data Quality Checks with Evidently\\n\\n## Ove...   \n",
       " 10  # Hugging Face Emotion Classification\\n\\n## Ov...   \n",
       " 11  # Creating a Custom Descriptor\\n\\n## How to Cr...   \n",
       " 12  # Best Practices for Implementing Regression M...   \n",
       " 13  # NDCG Function Parameters\\n\\n## NDCG Function...   \n",
       " 14  # Custom Parameters for Data Drift\\n\\n## Overv...   \n",
       " 15  # How to implement QuantileValue() in Evidentl...   \n",
       " 16  # Using DataDriftPreset in Python\\n\\n## Overvi...   \n",
       " 17  # Multiple Conditions in Tests\\n\\n## Overview ...   \n",
       " 18  # Tracely Library for Real-Time Data\\n\\n## Ove...   \n",
       " 19  # Impact of Telemetry on Evidently Development...   \n",
       " 20  # ValueStats() Metric Usage Examples\\n\\n## Ove...   \n",
       " 21  # Generating Reports from LLM Testing\\n\\n## Ov...   \n",
       " 22  # Creating RAG Evaluation Dataset Guide\\n\\n## ...   \n",
       " 23  # Excluding Tests in Evidently\\n\\n## How to Ex...   \n",
       " 24  # Automatically Mapping Columns in Evidently\\n...   \n",
       " 25  # BinaryClassificationPromptTemplate Usage\\n\\n...   \n",
       " \n",
       "                                              messages  tool_call_number  \\\n",
       " 0   [{'kind': 'user-prompt', 'content': 'how to us...                 7   \n",
       " 1   [{'kind': 'user-prompt', 'content': 'ColumnCou...                 3   \n",
       " 2   [{'kind': 'user-prompt', 'content': 'LLM judge...                 6   \n",
       " 3   [{'kind': 'user-prompt', 'content': 'Evidently...                 6   \n",
       " 4   [{'kind': 'user-prompt', 'content': 'how to be...                 7   \n",
       " 5   [{'kind': 'user-prompt', 'content': 'examples ...                 6   \n",
       " 6   [{'kind': 'user-prompt', 'content': 'performin...                 8   \n",
       " 7   [{'kind': 'user-prompt', 'content': 'examples ...                12   \n",
       " 8   [{'kind': 'user-prompt', 'content': 'example o...                 5   \n",
       " 9   [{'kind': 'user-prompt', 'content': 'data qual...                10   \n",
       " 10  [{'kind': 'user-prompt', 'content': 'HuggingFa...                 6   \n",
       " 11  [{'kind': 'user-prompt', 'content': 'how to cr...                 7   \n",
       " 12  [{'kind': 'user-prompt', 'content': 'best prac...                 5   \n",
       " 13  [{'kind': 'user-prompt', 'content': 'parameter...                 5   \n",
       " 14  [{'kind': 'user-prompt', 'content': 'custom pa...                 6   \n",
       " 15  [{'kind': 'user-prompt', 'content': 'how to im...                 9   \n",
       " 16  [{'kind': 'user-prompt', 'content': 'how to ru...                 8   \n",
       " 17  [{'kind': 'user-prompt', 'content': 'multiple ...                 6   \n",
       " 18  [{'kind': 'user-prompt', 'content': 'Tracely l...                 6   \n",
       " 19  [{'kind': 'user-prompt', 'content': 'Impact of...                 6   \n",
       " 20  [{'kind': 'user-prompt', 'content': 'examples ...                 6   \n",
       " 21  [{'kind': 'user-prompt', 'content': 'get repor...                 7   \n",
       " 22  [{'kind': 'user-prompt', 'content': 'creating ...                 6   \n",
       " 23  [{'kind': 'user-prompt', 'content': 'how to ex...                 5   \n",
       " 24  [{'kind': 'user-prompt', 'content': 'automatic...                11   \n",
       " 25  [{'kind': 'user-prompt', 'content': 'use of Bi...                 4   \n",
       " \n",
       "     requests                                  original_question  \\\n",
       " 0          3  {'question': 'how to use TextEvals() in Eviden...   \n",
       " 1          3  {'question': 'ColumnCount() metric usage', 'su...   \n",
       " 2          3  {'question': 'LLM judge metrics customization'...   \n",
       " 3          3  {'question': 'Evidently telemetry version 0.4....   \n",
       " 4          3  {'question': 'how to benchmark model quality w...   \n",
       " 5          3  {'question': 'examples of JSONSchemaMatch', 's...   \n",
       " 6          3  {'question': 'performing quality checks on dat...   \n",
       " 7          4  {'question': 'examples of incorrect LLM respon...   \n",
       " 8          6  {'question': 'example of mapping regression co...   \n",
       " 9          4  {'question': 'data quality checks with evident...   \n",
       " 10         2  {'question': 'HuggingFace emotion classificati...   \n",
       " 11         3  {'question': 'how to create a custom descripto...   \n",
       " 12         3  {'question': 'best practices for implementing ...   \n",
       " 13         3  {'question': 'parameters needed for NDCG()', '...   \n",
       " 14         3  {'question': 'custom parameters for data drift...   \n",
       " 15         3  {'question': 'how to implement QuantileValue()...   \n",
       " 16         3  {'question': 'how to run DataDriftPreset in Py...   \n",
       " 17         2  {'question': 'multiple conditions in tests', '...   \n",
       " 18         2  {'question': 'Tracely library real-time data',...   \n",
       " 19         3  {'question': 'Impact of telemetry on Evidently...   \n",
       " 20         2  {'question': 'examples of ValueStats() metric ...   \n",
       " 21         3  {'question': 'get reports from LLM testing', '...   \n",
       " 22         2  {'question': 'creating RAG evaluation dataset ...   \n",
       " 23         2  {'question': 'how to exclude tests in evidentl...   \n",
       " 24        10  {'question': 'automatically mapping columns in...   \n",
       " 25         3  {'question': 'use of BinaryClassificationPromp...   \n",
       " \n",
       "                                       original_result  \n",
       " 0   AgentRunResult(output=SearchResultArticle(foun...  \n",
       " 1   AgentRunResult(output=SearchResultArticle(foun...  \n",
       " 2   AgentRunResult(output=SearchResultArticle(foun...  \n",
       " 3   AgentRunResult(output=SearchResultArticle(foun...  \n",
       " 4   AgentRunResult(output=SearchResultArticle(foun...  \n",
       " 5   AgentRunResult(output=SearchResultArticle(foun...  \n",
       " 6   AgentRunResult(output=SearchResultArticle(foun...  \n",
       " 7   AgentRunResult(output=SearchResultArticle(foun...  \n",
       " 8   AgentRunResult(output=SearchResultArticle(foun...  \n",
       " 9   AgentRunResult(output=SearchResultArticle(foun...  \n",
       " 10  AgentRunResult(output=SearchResultArticle(foun...  \n",
       " 11  AgentRunResult(output=SearchResultArticle(foun...  \n",
       " 12  AgentRunResult(output=SearchResultArticle(foun...  \n",
       " 13  AgentRunResult(output=SearchResultArticle(foun...  \n",
       " 14  AgentRunResult(output=SearchResultArticle(foun...  \n",
       " 15  AgentRunResult(output=SearchResultArticle(foun...  \n",
       " 16  AgentRunResult(output=SearchResultArticle(foun...  \n",
       " 17  AgentRunResult(output=SearchResultArticle(foun...  \n",
       " 18  AgentRunResult(output=SearchResultArticle(foun...  \n",
       " 19  AgentRunResult(output=SearchResultArticle(foun...  \n",
       " 20  AgentRunResult(output=SearchResultArticle(foun...  \n",
       " 21  AgentRunResult(output=SearchResultArticle(foun...  \n",
       " 22  AgentRunResult(output=SearchResultArticle(foun...  \n",
       " 23  AgentRunResult(output=SearchResultArticle(foun...  \n",
       " 24  AgentRunResult(output=SearchResultArticle(foun...  \n",
       " 25  AgentRunResult(output=SearchResultArticle(foun...  ,\n",
       " 'df_eval':                                              question  \\\n",
       " 0          automatically mapping columns in Evidently   \n",
       " 1                   how to create a custom descriptor   \n",
       " 2                        parameters needed for NDCG()   \n",
       " 3                          ColumnCount() metric usage   \n",
       " 4                   how to exclude tests in evidently   \n",
       " 5                 how to use TextEvals() in Evidently   \n",
       " 6                  HuggingFace emotion classification   \n",
       " 7   best practices for implementing regression met...   \n",
       " 8        Impact of telemetry on Evidently development   \n",
       " 9   how to benchmark model quality with dummy metrics   \n",
       " 10                     Tracely library real-time data   \n",
       " 11              examples of ValueStats() metric usage   \n",
       " 12          use of BinaryClassificationPromptTemplate   \n",
       " 13                   custom parameters for data drift   \n",
       " 14                  Evidently telemetry version 0.4.0   \n",
       " 15              performing quality checks on datasets   \n",
       " 16               how to run DataDriftPreset in Python   \n",
       " 17                   how to implement QuantileValue()   \n",
       " 18                        examples of JSONSchemaMatch   \n",
       " 19                examples of incorrect LLM responses   \n",
       " 20              creating RAG evaluation dataset guide   \n",
       " 21                       multiple conditions in tests   \n",
       " 22                    LLM judge metrics customization   \n",
       " 23                       get reports from LLM testing   \n",
       " 24  example of mapping regression columns in Evide...   \n",
       " 25                 data quality checks with evidently   \n",
       " \n",
       "    CheckName.tool_call_search CheckName.instructions_follow  \\\n",
       " 0                        True                          True   \n",
       " 1                         NaN                           NaN   \n",
       " 2                         NaN                           NaN   \n",
       " 3                       False                          True   \n",
       " 4                         NaN                           NaN   \n",
       " 5                         NaN                           NaN   \n",
       " 6                         NaN                           NaN   \n",
       " 7                        True                          True   \n",
       " 8                        True                          True   \n",
       " 9                         NaN                           NaN   \n",
       " 10                        NaN                           NaN   \n",
       " 11                       True                          True   \n",
       " 12                        NaN                           NaN   \n",
       " 13                        NaN                           NaN   \n",
       " 14                       True                          True   \n",
       " 15                        NaN                          True   \n",
       " 16                       True                          True   \n",
       " 17                        NaN                           NaN   \n",
       " 18                       True                          True   \n",
       " 19                       True                           NaN   \n",
       " 20                       True                          True   \n",
       " 21                        NaN                           NaN   \n",
       " 22                       True                          True   \n",
       " 23                       True                          True   \n",
       " 24                        NaN                           NaN   \n",
       " 25                       True                          True   \n",
       " \n",
       "    CheckName.instructions_avoid CheckName.answer_relevant  \\\n",
       " 0                           NaN                       NaN   \n",
       " 1                           NaN                       NaN   \n",
       " 2                           NaN                       NaN   \n",
       " 3                          True                     False   \n",
       " 4                           NaN                       NaN   \n",
       " 5                           NaN                       NaN   \n",
       " 6                           NaN                       NaN   \n",
       " 7                          True                     False   \n",
       " 8                          True                      True   \n",
       " 9                           NaN                       NaN   \n",
       " 10                          NaN                       NaN   \n",
       " 11                         True                      True   \n",
       " 12                          NaN                       NaN   \n",
       " 13                          NaN                       NaN   \n",
       " 14                         True                       NaN   \n",
       " 15                         True                       NaN   \n",
       " 16                         True                      True   \n",
       " 17                          NaN                       NaN   \n",
       " 18                         True                       NaN   \n",
       " 19                          NaN                       NaN   \n",
       " 20                         True                       NaN   \n",
       " 21                          NaN                       NaN   \n",
       " 22                         True                      True   \n",
       " 23                         True                      True   \n",
       " 24                          NaN                       NaN   \n",
       " 25                         True                      True   \n",
       " \n",
       "    CheckName.answer_clear CheckName.answer_match CheckName.answer_citations  \\\n",
       " 0                     NaN                    NaN                        NaN   \n",
       " 1                     NaN                    NaN                        NaN   \n",
       " 2                     NaN                    NaN                        NaN   \n",
       " 3                   False                  False                      False   \n",
       " 4                     NaN                    NaN                        NaN   \n",
       " 5                     NaN                    NaN                        NaN   \n",
       " 6                     NaN                    NaN                        NaN   \n",
       " 7                   False                  False                      False   \n",
       " 8                    True                   True                       True   \n",
       " 9                     NaN                    NaN                        NaN   \n",
       " 10                    NaN                    NaN                        NaN   \n",
       " 11                   True                   True                       True   \n",
       " 12                    NaN                    NaN                        NaN   \n",
       " 13                    NaN                    NaN                        NaN   \n",
       " 14                    NaN                    NaN                        NaN   \n",
       " 15                    NaN                    NaN                        NaN   \n",
       " 16                   True                   True                       True   \n",
       " 17                    NaN                    NaN                        NaN   \n",
       " 18                    NaN                    NaN                        NaN   \n",
       " 19                    NaN                    NaN                        NaN   \n",
       " 20                    NaN                    NaN                        NaN   \n",
       " 21                    NaN                    NaN                        NaN   \n",
       " 22                   True                   True                       True   \n",
       " 23                   True                   True                       True   \n",
       " 24                    NaN                    NaN                        NaN   \n",
       " 25                    NaN                    NaN                        NaN   \n",
       " \n",
       "    CheckName.completeness  \n",
       " 0                     NaN  \n",
       " 1                     NaN  \n",
       " 2                     NaN  \n",
       " 3                   False  \n",
       " 4                     NaN  \n",
       " 5                     NaN  \n",
       " 6                     NaN  \n",
       " 7                   False  \n",
       " 8                    True  \n",
       " 9                     NaN  \n",
       " 10                    NaN  \n",
       " 11                   True  \n",
       " 12                    NaN  \n",
       " 13                    NaN  \n",
       " 14                    NaN  \n",
       " 15                    NaN  \n",
       " 16                   True  \n",
       " 17                    NaN  \n",
       " 18                    NaN  \n",
       " 19                    NaN  \n",
       " 20                    NaN  \n",
       " 21                    NaN  \n",
       " 22                   True  \n",
       " 23                   True  \n",
       " 24                    NaN  \n",
       " 25                    NaN  ,\n",
       " 'metrics': CheckName.tool_call_search       0.923077\n",
       " CheckName.instructions_follow         1.0\n",
       " CheckName.instructions_avoid          1.0\n",
       " CheckName.answer_relevant            0.75\n",
       " CheckName.answer_clear           0.714286\n",
       " CheckName.answer_match           0.714286\n",
       " CheckName.answer_citations       0.714286\n",
       " CheckName.completeness           0.714286\n",
       " dtype: object,\n",
       " 'duration_seconds': 104.057046,\n",
       " 'timestamp': datetime.datetime(2025, 10, 27, 14, 12, 20, 899371)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await run_full_evaluation(agent, csv_path='../evals/gt-sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba0f488-e48d-4ca2-8ac2-1c970ee13953",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
